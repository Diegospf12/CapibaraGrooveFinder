# Capibara Groove Findes
Proyecto 3 del curso de Base de datos 2. Construcci贸n del 铆ndice invertido textual y multidimensional

# Team - Group 5
| <a href="https://github.com/anamariaaccilio" target="_blank">**Ana Maria Accilio Villanueva**</a> | <a href="https://github.com/Diegospf12" target="_blank">**Diego Pacheco Ferrel**</a> | <a href="https://github.com/juanpedrovv" target="_blank">**Juan Pedro Vasquez Vilchez**</a> | <a href="https://github.com/LuisEnriqueCortijoGonzales" target="_blank">**Luis Enrique Cortijo Gonzales**</a> | <a href="https://github.com/marceloZS" target="_blank">**Marcelo Mario Zuloeta Salazar**</a> |
| :----------------------------------------------------------------------------------------------: | :----------------------------------------------------------------------------------: | :-----------------------------------------------------------------------------------------: | :-------------------------------------------------------------------------------------------------------------: | :------------------------------------------------------------------------------------------: |
| <img src="https://avatars.githubusercontent.com/u/91237434?v=4" alt="drawing" width="200"/> | <img src="https://avatars.githubusercontent.com/u/94090499?v=4" alt="drawing" width="200"/> | <img src="https://avatars.githubusercontent.com/u/83739305?v=4" alt="drawing" width="200"/> | <img src="https://avatars.githubusercontent.com/u/84096868?v=4" alt="drawing" width="200"/> | <img src="https://avatars.githubusercontent.com/u/85197213?v=4" alt="drawing" width="200"/> |

<a name="readme-top"></a>
<details open>
  <summary><h2>Tabla de contenidos:<h2></summary>
  <ul>
    <li><a href="#Introducci贸n-">Introducci贸n 
      <ul>
        <li><a href="#objetivo-del-proyecto">Objetivo del proyecto</a></li>
        <li><a href="#Dominio-de-datos">Dominio de datos</a></li>
        <li><a href="#Importacia-de-aplicar-indexaci贸n">Importancia de aplicar indexaci贸n</a></li>
      </ul>
    </a></li> 
    <li><a href="#Estructura-del-proyecto">Estructura del proyecto</a></li>
    <li><a href="#Backend-(ndice-Invertido)">Backend (ndice Invertido)</a></li>
    <li><a href="#Backend-(ndice-Multidimensional)">Backend (ndice Multidimensional)</a></li>
    <li><a href="#Frontend-(GUI)">Frontend (GUI)</a></li>
    <li><a href="#驴C贸mo-se-construye-el-铆ndice-invertido-en-PostgreSQL?">驴C贸mo se construye el 铆ndice invertido en PostgreSQL?</a></li>
    <li><a href="#Experimentaci贸n">Experimentaci贸n</a></li>
    <li><a href="#conclusiones">Conclusiones</a></li>
    <li><a href="#referencias-bibliogr谩ficas">Referencias bibliogr谩ficas</a></li>
</details>

<hr>

# Introducci贸n

## ndice invertido textual
El 铆ndice invertido es una estructura de datos utilizada en motores de b煤squeda y sistemas de recuperaci贸n de informaci贸n. Consiste en un diccionario que mapea t茅rminos a una lista de documentos en los que aparecen esos t茅rminos. Esta estructura permite una b煤squeda eficiente de documentos que contengan ciertos t茅rminos clave. 

## ndice multidimensional
Un 铆ndice multidimensional es una estructura de datos que permite organizar y acceder a informaci贸n en m煤ltiples dimensiones. Se utiliza para representar y buscar datos que tienen m煤ltiples atributos o caracter铆sticas.

## Objetivo del proyecto
El presente proyecto tiene como objetivo desarrollar estas estructuras de datos de manera eficiente, con motivo de realizar b煤squedas r谩pidas en un conjunto de documentos.
Con respecto al 铆ndice invertido textual, se utiliza para asociar t茅rminos de consulta con los documentos que los contienen ya que mejora la velocidad y precisi贸n del retorno de informaci贸n, lo que facilita la recuperaci贸n eficiente de documentos relevantes en funci贸n de los t茅rminos de b煤squeda.
En cuanto al 铆ndice multidimensional, se utilizar para representar caracter铆sticas tanto de texto como de audio, lo que permite realizar consultas que involucren m煤ltiples dimensiones, como la similitud de texto y audio en funci贸n de diferentes atributos.

## Dominio de datos
La base de datos utilizada es la Fashion Product Images. Esta contiene alrededor de 44 mil productos etiquetados por ID, categor铆a, g茅nero, color, a帽o, etc.

## Importancia de aplicar indexaci贸n
La indexaci贸n es fundamental por las siguientes razones:
1. Recuperaci贸n eficiente de informaci贸n: La indexaci贸n permite realizar b煤squedas r谩pidas en grandes conjuntos de datos, lo que es esencial para la recuperaci贸n eficiente de documentos relevantes en funci贸n de consultas de texto y audio.

2. Optimizaci贸n de consultas: Al indexar los datos, se pueden optimizar las consultas para que se ejecuten de manera m谩s eficiente, lo que es crucial para aplicaciones en tiempo real, como la recuperaci贸n de informaci贸n en sistemas de b煤squeda.

3. Reducci贸n de la complejidad computacional: La indexaci贸n puede reducir la complejidad computacional de las operaciones de b煤squeda y an谩lisis de datos, lo que es importante para garantizar un rendimiento 贸ptimo del sistema, especialmente en aplicaciones que manejan grandes vol煤menes de informaci贸n.

# Estructura del proyecto
El algoritmo SPIMI (Single-Pass In-Memory Indexing) es un m茅todo utilizado para construir un 铆ndice invertido durante el proceso de indexaci贸n de grandes conjuntos de datos. A diferencia de algunos algoritmos de indexaci贸n que requieren m煤ltiples pasadas sobre los datos, SPIMI realiza la construcci贸n del 铆ndice en una sola pasada a trav茅s de los datos.

![spimi1](https://github.com/marceloZS/Full-Text-Search_Project2/blob/main/imagenes/spimi1.jpg)

Se calcula una sola vez la longitud de cada documento, y se lee el documento de entrada uno a uno (por ejemplo, un documento de texto) y se tokeniza en t茅rminos individuales. Cada t茅rmino se procesa por separado.

![spimi2](https://github.com/marceloZS/Full-Text-Search_Project2/blob/main/imagenes/spimi2.jpeg)


# Backend (ndice Invertido)
El archivo inverted_index.py contiene la implementaci贸n del 铆ndice invertido utilizando el algoritmo SPIMI (Single-Pass In-Memory Indexing). El algoritmo SPIMI divide el proceso de indexaci贸n en bloques m谩s peque帽os para manejar grandes vol煤menes de datos de manera eficiente.

El c贸digo incluye las siguientes funciones principales:

1. spimi_invert(): Esta funci贸n realiza la indexaci贸n de los documentos presentes en una carpeta de entrada. Utiliza el algoritmo SPIMI para generar el 铆ndice invertido.

2. binary_search_term_blocks(): Esta funci贸n realiza una b煤squeda binaria en los bloques del 铆ndice invertido para encontrar un t茅rmino espec铆fico. Utiliza una implementaci贸n eficiente de b煤squeda binaria para mejorar el rendimiento de la b煤squeda.

3. cosine_similarity(): Esta funci贸n calcula la similitud de coseno entre una consulta y los documentos indexados. Utiliza el 铆ndice invertido y los pesos TF-IDF para calcular la similitud de coseno.

## 1. MTODO SPIMI INVERT()

```python

def spimi_invert(self):
        documents = os.listdir(self.input_folder)
        documents_count = len(documents)
        documents_counter = 0
        block_number = 0

        for docID in documents:
            if docID.endswith(".txt"):
                documents_counter += 1
                file_route = os.path.join(self.input_folder, docID)
                file_content = open(file_route, encoding="utf-8").read().lower()

```

Leemos uno a uno de nuestros documentos no pre-procesados

```python
                '''Pre-processing'''
                # Tokenizamos nuestro txt
                tokens = nltk.word_tokenize(file_content)
                #Filtramos para que no pertenezca a los stopwords o no sea un valor no alfanumerico (Stopwords / Valores raros)
                terms = [word for word in tokens if not word in TextPreprocessor.stopwords and re.match("^[a-zA-Z]+$", word)]
                #Hacemos Stemming en el idioma respectivo
                terms = [TextPreprocessor.stemmer.stem(w) for w in terms]
```
Una vez obtenemos el documento no procesado:
- Lo tokenizamos
- Filtramos las Stopwords
- Hacemos Stemming

```python
                for term in terms:

                    if (sys.getsizeof(term) + sys.getsizeof([docID]) + sys.getsizeof(self.dictionary) > self.block_size_limit):
                        temp_dict = self.sort_terms()
                        self.write_block_to_disk(temp_dict, block_number)
                        temp_dict = {}
                        block_number += 1

                    if term not in self.dictionary:
                        self.dictionary[term] = [docID]
                    else:
                        self.dictionary[term].append(docID)

                if sys.getsizeof(self.dictionary) > self.block_size_limit or (documents_counter == documents_count - 1):
                    temp_dict = self.sort_terms()
                    self.write_block_to_disk(temp_dict, block_number)
                    temp_dict = {}
                    block_number += 1
```

Una vez ya pre-procesado el documento, leemos uno a uno los t茅rminos de este, y los vamos agregando al diccionario de la siguiente forma:

```python
diccionario = {'baron':['doc1278.txt', 'doc1299.txt'],
        'zascuss':['doc1278.txt'],
        'abbi': ['doc1299.txt'],
        'abraim' : ['doc12081.txt']
}
```

Una vez este diccionario llegue al l铆mite de RAM:

- Ordenaremos este diccionario en orden alfab茅tico (sort_terms(self))
- y agregaremos su term frequency de la siguiente forma (sort_terms(self) llama al m茅todo calculate_tftd(self, pl_with_duplicates)):

```python
diccionario_temporal = {    'aaron':[['doc11987.txt', 1]],
                            'abascuss':[['doc1278.txt', 1], ['doc1998.txt', 6]],
                            'abbi':[['doc1299.txt', 2]],
                            'abf':[['doc1156.txt', 3]],
                            'abraim':[['doc12081.txt', 1]]  }
```
- Finalmente, este diccionario modificado lo cargamos a memoria secundaria con el m茅todo write_block_to_disk(self, term_postings_list, block_number), generando as铆 un bloque (indice invertido local).

**Una vez se hayan terminado de procesar todos los documentos, y con ello haber creado todos los bloques, mergearemos todos estos bloques para crear un indice invertido global repartido en los n bloques.**

```python
        print("BLOCKS creation complete!")
        self.merge_blocks()
```

```python
Insertar codigo de merge blocks


```
Explicar c贸digo de merge blocks



## Ejecuci贸n 贸ptima de consultas aplicando similitud de coseno



## 驴C贸mo se construye el 铆ndice invertido en PostgreSQL?

A grandes rasgos, para la construcci贸n del 铆ndice invertido en PostgreSQL se necesitan 3 tablas principales.
- Una tabla para almacenar los documentos
- Una tabla para almacenar los t茅rminos
- Una tabla de relaci贸n entre t茅rminos y documentos

A partir de esto, se requere extraer los t茅rminos de los documentos y almacenarlos en una tabla de t茅rminos. Por ejemplo, se tiene lo siguiente:
```sql
INSERT INTO terms (term)
SELECT DISTINCT unnest(string_to_array(lower(content), ' ')) AS term
FROM documents;
```

La funci贸n string_to_array se utiliza para dividir el contenido de los documentos en t茅rminos individuales, y la funci贸n unnest se utiliza para convertir el resultado en filas individuales.

Lo siguiente es armar la relaci贸n entre los documentos y t茅rminos. Esto se puede lograr utilizando consultas SQL que identifiquen los t茅rminos que aparecen en cada documento y los almacenen en la tabla de relaci贸n. Por ejemplo:
```sql
INSERT INTO document_term (document_id, term)
SELECT d.id, t.term
FROM documents d
JOIN terms t ON lower(d.content) LIKE '%' || t.term || '%';
```
Una vez que se han extra铆do los t茅rminos y se ha creado la tabla de relaci贸n, se pueden crear 铆ndices en las columnas relevantes para mejorar el rendimiento de las consultas de b煤squeda. Por lo general, se crean 铆ndices en las columnas de t茅rminos y en las columnas de identificadores de documentos para acelerar las b煤squedas.

Con el 铆ndice invertido ya constru铆do se pueden realizar consultas de b煤squeda utilizando cl谩usulas SQL como WHERE y JOIN. Estas consultas aprovechan los 铆ndices para buscar r谩pidamente los documentos que contienen los t茅rminos de b煤squeda especificados. Por tal motivo, las b煤squedas de texto se vuelven m谩s eficientes, ya que se evita la necesidad de realizar exploraciones completas de los documentos.

# Backend (ndice Multidimensional)



## KNN Secuencial: Priority Queue Search y Range Search



## KNN RTree



## KNN High D: Mitigaci贸n de la dimensionalidad con FAISS



# Frontend (GUI)

## Mini-manual de usuarios
### Paso 1: Clonar el Repositorio

```bash
git clone https://github.com/Diegospf12/CapibaraGrooveFinder
cd CapibaraGrooveFinder
```

### Paso 2: Configuraci贸n del Backend

Instalar dependencias
```bash
cd backend
source venv/bin/activate
pip install -r requirements.txt
```

Ejecutar servidor
```bash
cd backend
pip install -r requirements.txt
uvicorn main:app --reload
```

### Paso 3: Configuraci贸n del Frontend

Instalar dependencias
```bash
cd frontend
npm install
npm run serve
```

## Screenshots
![[Main page]](https://github.com/Diegospf12/CapibaraGrooveFinder/blob/main/images/main.png)
![[Lyrics page]](https://github.com/Diegospf12/CapibaraGrooveFinder/blob/main/images/lyrics.png)
![[Similar page]](https://github.com/Diegospf12/CapibaraGrooveFinder/blob/main/images/similarpage.png)

## An谩lisis comparativo visual con otras implementaciones

# Experimentaci贸n

## Tablas y gr谩ficos de los resultados experimentales

|      | Implementaci贸n | Postgress |
|------|----------------|-----------|
| 1000 |     15 ms      |   19 ms   |
| 2000 |     34 ms      |   33 ms   |
| 4000 |     65 ms      |   72 ms   |
| 8000 |    190 ms      |  180 ms   |
|16000 |    295 ms      |  300 ms   |
|32000 |    333 ms      |  359 ms   |
|64000 |    380 ms      |  360 ms   |

### Implementaci贸n de ndice Invertido

Nuestra implementaci贸n personalizada de 铆ndice invertido ha demostrado ser eficiente en la b煤squeda de datos basada en texto. Hemos medido el rendimiento de nuestra implementaci贸n en milisegundos para una variedad de tama帽os de datos de prueba, desde 1,000 hasta 64,000 registros. 

### PostgreSQL con ndice Invertido

Por otro lado, hemos utilizado PostgreSQL con sus propios 铆ndices invertidos para realizar b煤squedas de texto similares a nuestras pruebas con datos de prueba de tama帽os comparables.

### Discusi贸n

### Conclusi贸n

Los resultados de nuestra comparaci贸n indican que PostgreSQL supera ligeramente a nuestra implementaci贸n personalizada de 铆ndice invertido en t茅rminos de rendimiento en la mayor铆a de los escenarios. Aunque nuestra implementaci贸n es eficiente, PostgreSQL, con su optimizaci贸n interna y capacidad para manejar grandes conjuntos de datos, muestra tiempos de b煤squeda ligeramente m谩s bajos en las pruebas.
