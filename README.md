# Capibara Groove Finder
Proyecto 3 del curso de Base de datos 2. Construcci√≥n del √≠ndice invertido textual y multidimensional

# Team - Group 5
| <a href="https://github.com/anamariaaccilio" target="_blank">**Ana Maria Accilio Villanueva**</a> | <a href="https://github.com/Diegospf12" target="_blank">**Diego Pacheco Ferrel**</a> | <a href="https://github.com/juanpedrovv" target="_blank">**Juan Pedro Vasquez Vilchez**</a> | <a href="https://github.com/LuisEnriqueCortijoGonzales" target="_blank">**Luis Enrique Cortijo Gonzales**</a> | <a href="https://github.com/marceloZS" target="_blank">**Marcelo Mario Zuloeta Salazar**</a> |
| :----------------------------------------------------------------------------------------------: | :----------------------------------------------------------------------------------: | :-----------------------------------------------------------------------------------------: | :-------------------------------------------------------------------------------------------------------------: | :------------------------------------------------------------------------------------------: |
| <img src="https://avatars.githubusercontent.com/u/91237434?v=4" alt="drawing" width="200"/> | <img src="https://avatars.githubusercontent.com/u/94090499?v=4" alt="drawing" width="200"/> | <img src="https://avatars.githubusercontent.com/u/83739305?v=4" alt="drawing" width="200"/> | <img src="https://avatars.githubusercontent.com/u/84096868?v=4" alt="drawing" width="200"/> | <img src="https://avatars.githubusercontent.com/u/85197213?v=4" alt="drawing" width="200"/> |

<a name="readme-top"></a>
<details open>
  <summary><h2>Tabla de contenidos:<h2></summary>
  <ul>
    <li><a href="#Introducci√≥n-üñä">Introducci√≥n üñä
      <ul>
        <li><a href="#objetivo-del-proyecto">Objetivo del proyecto</a></li>
        <li><a href="#Dominio-de-datos">Dominio de datos</a></li>
        <li><a href="#Importacia-de-aplicar-indexaci√≥n">Importancia de aplicar indexaci√≥n</a></li>
      </ul>
    </a></li> 
    <li><a href="#Estructura-del-proyecto">Estructura del proyecto</a></li>
    <li><a href="#Backend-(√çndice-Invertido)">Backend (√çndice Invertido)</a></li>
    <li><a href="#Backend-(√çndice-Multidimensional)">Backend (√çndice Multidimensional)</a></li>
    <li><a href="#Frontend-(GUI)">Frontend (GUI)</a></li>
    <li><a href="#¬øC√≥mo-se-construye-el-√≠ndice-invertido-en-PostgreSQL?">¬øC√≥mo se construye el √≠ndice invertido en PostgreSQL?</a></li>
    <li><a href="#Experimentaci√≥n">Experimentaci√≥n</a></li>
    <li><a href="#conclusiones">Conclusiones</a></li>
    <li><a href="#referencias-bibliogr√°ficas">Referencias bibliogr√°ficas</a></li>
</details>

<hr>

# Introducci√≥n

## √çndice invertido textual
El √≠ndice invertido es una estructura de datos utilizada en motores de b√∫squeda y sistemas de recuperaci√≥n de informaci√≥n. Consiste en un diccionario que mapea t√©rminos a una lista de documentos en los que aparecen esos t√©rminos. Esta estructura permite una b√∫squeda eficiente de documentos que contengan ciertos t√©rminos clave. 

## √çndice multidimensional
Un √≠ndice multidimensional es una estructura de datos que permite organizar y acceder a informaci√≥n en m√∫ltiples dimensiones. Se utiliza para representar y buscar datos que tienen m√∫ltiples atributos o caracter√≠sticas.

## Objetivo del proyecto
El presente proyecto tiene como objetivo desarrollar estas estructuras de datos de manera eficiente, con motivo de realizar b√∫squedas r√°pidas en un conjunto de documentos.
Con respecto al √≠ndice invertido textual, se utiliza para asociar t√©rminos de consulta con los documentos que los contienen ya que mejora la velocidad y precisi√≥n del retorno de informaci√≥n, lo que facilita la recuperaci√≥n eficiente de documentos relevantes en funci√≥n de los t√©rminos de b√∫squeda.
En cuanto al √≠ndice multidimensional, se utilizar para representar caracter√≠sticas tanto de texto como de audio, lo que permite realizar consultas que involucren m√∫ltiples dimensiones, como la similitud de texto y audio en funci√≥n de diferentes atributos.

## Dominio de datos
La base de datos utilizada es la Fashion Product Images. Esta contiene alrededor de 44 mil productos etiquetados por ID, categor√≠a, g√©nero, color, a√±o, etc.

## Importancia de aplicar indexaci√≥n
La indexaci√≥n es fundamental por las siguientes razones:
1. Recuperaci√≥n eficiente de informaci√≥n: La indexaci√≥n permite realizar b√∫squedas r√°pidas en grandes conjuntos de datos, lo que es esencial para la recuperaci√≥n eficiente de documentos relevantes en funci√≥n de consultas de texto y audio.

2. Optimizaci√≥n de consultas: Al indexar los datos, se pueden optimizar las consultas para que se ejecuten de manera m√°s eficiente, lo que es crucial para aplicaciones en tiempo real, como la recuperaci√≥n de informaci√≥n en sistemas de b√∫squeda.

3. Reducci√≥n de la complejidad computacional: La indexaci√≥n puede reducir la complejidad computacional de las operaciones de b√∫squeda y an√°lisis de datos, lo que es importante para garantizar un rendimiento √≥ptimo del sistema, especialmente en aplicaciones que manejan grandes vol√∫menes de informaci√≥n.

# Estructura del proyecto
El algoritmo SPIMI (Single-Pass In-Memory Indexing) es un m√©todo utilizado para construir un √≠ndice invertido durante el proceso de indexaci√≥n de grandes conjuntos de datos. A diferencia de algunos algoritmos de indexaci√≥n que requieren m√∫ltiples pasadas sobre los datos, SPIMI realiza la construcci√≥n del √≠ndice en una sola pasada a trav√©s de los datos.

![spimi1](https://github.com/marceloZS/Full-Text-Search_Project2/blob/main/imagenes/spimi1.jpg)

Se calcula una sola vez la longitud de cada documento, y se lee el documento de entrada uno a uno (por ejemplo, un documento de texto) y se tokeniza en t√©rminos individuales. Cada t√©rmino se procesa por separado.

![spimi2](https://github.com/marceloZS/Full-Text-Search_Project2/blob/main/imagenes/spimi2.jpeg)


# Backend (√çndice Invertido)
El archivo inverted_index.py contiene la implementaci√≥n del √≠ndice invertido utilizando el algoritmo SPIMI (Single-Pass In-Memory Indexing). El algoritmo SPIMI divide el proceso de indexaci√≥n en bloques m√°s peque√±os para manejar grandes vol√∫menes de datos de manera eficiente.

El c√≥digo incluye las siguientes funciones principales:

1. spimi_invert(): Esta funci√≥n realiza la indexaci√≥n de los documentos presentes en una carpeta de entrada. Utiliza el algoritmo SPIMI para generar el √≠ndice invertido.

2. binary_search_term_blocks(): Esta funci√≥n realiza una b√∫squeda binaria en los bloques del √≠ndice invertido para encontrar un t√©rmino espec√≠fico. Utiliza una implementaci√≥n eficiente de b√∫squeda binaria para mejorar el rendimiento de la b√∫squeda.

3. cosine_similarity(): Esta funci√≥n calcula la similitud de coseno entre una consulta y los documentos indexados. Utiliza el √≠ndice invertido y los pesos TF-IDF para calcular la similitud de coseno.

## 1. M√âTODO SPIMI INVERT()

```python

def spimi_invert(self):
        documents = os.listdir(self.input_folder)
        documents_count = len(documents)
        documents_counter = 0
        block_number = 0

        for docID in documents:
            if docID.endswith(".txt"):
                documents_counter += 1
                file_route = os.path.join(self.input_folder, docID)
                file_content = open(file_route, encoding="utf-8").read().lower()

```

Leemos uno a uno de nuestros documentos no pre-procesados

```python
                '''Pre-processing'''
                # Tokenizamos nuestro txt
                tokens = nltk.word_tokenize(file_content)
                #Filtramos para que no pertenezca a los stopwords o no sea un valor no alfanumerico (Stopwords / Valores raros)
                terms = [word for word in tokens if not word in TextPreprocessor.stopwords and re.match("^[a-zA-Z]+$", word)]
                #Hacemos Stemming en el idioma respectivo
                terms = [TextPreprocessor.stemmer.stem(w) for w in terms]
```
Una vez obtenemos el documento no procesado:
- Lo tokenizamos
- Filtramos las Stopwords
- Hacemos Stemming

```python
                for term in terms:

                    if (sys.getsizeof(term) + sys.getsizeof([docID]) + sys.getsizeof(self.dictionary) > self.block_size_limit):
                        temp_dict = self.sort_terms()
                        self.write_block_to_disk(temp_dict, block_number)
                        temp_dict = {}
                        block_number += 1

                    if term not in self.dictionary:
                        self.dictionary[term] = [docID]
                    else:
                        self.dictionary[term].append(docID)

                if sys.getsizeof(self.dictionary) > self.block_size_limit or (documents_counter == documents_count - 1):
                    temp_dict = self.sort_terms()
                    self.write_block_to_disk(temp_dict, block_number)
                    temp_dict = {}
                    block_number += 1
```

Una vez ya pre-procesado el documento, leemos uno a uno los t√©rminos de este, y los vamos agregando al diccionario de la siguiente forma:

```python
diccionario = {'baron':['doc1278.txt', 'doc1299.txt'],
        'zascuss':['doc1278.txt'],
        'abbi': ['doc1299.txt'],
        'abraim' : ['doc12081.txt']
}
```

Una vez este diccionario llegue al l√≠mite de RAM:

- Ordenaremos este diccionario en orden alfab√©tico (sort_terms(self))
- y agregaremos su term frequency de la siguiente forma (sort_terms(self) llama al m√©todo calculate_tftd(self, pl_with_duplicates)):

```python
diccionario_temporal = {    'aaron':[['doc11987.txt', 1]],
                            'abascuss':[['doc1278.txt', 1], ['doc1998.txt', 6]],
                            'abbi':[['doc1299.txt', 2]],
                            'abf':[['doc1156.txt', 3]],
                            'abraim':[['doc12081.txt', 1]]  }
```
- Finalmente, este diccionario modificado lo cargamos a memoria secundaria con el m√©todo write_block_to_disk(self, term_postings_list, block_number), generando as√≠ un bloque (indice invertido local).

**Una vez se hayan terminado de procesar todos los documentos, y con ello haber creado todos los bloques, mergearemos todos estos bloques para crear un indice invertido global repartido en los n bloques.**

```python
        print("BLOCKS creation complete!")
        self.merge_blocks()
```

```python
Insertar codigo de merge blocks


```
Explicar c√≥digo de merge blocks



## Ejecuci√≥n √≥ptima de consultas aplicando similitud de coseno



## ¬øC√≥mo se construye el √≠ndice invertido en PostgreSQL?

A grandes rasgos, para la construcci√≥n del √≠ndice invertido en PostgreSQL se necesitan 3 tablas principales.
- Una tabla para almacenar los documentos
- Una tabla para almacenar los t√©rminos
- Una tabla de relaci√≥n entre t√©rminos y documentos

A partir de esto, se requere extraer los t√©rminos de los documentos y almacenarlos en una tabla de t√©rminos. Por ejemplo, se tiene lo siguiente:
```sql
INSERT INTO terms (term)
SELECT DISTINCT unnest(string_to_array(lower(content), ' ')) AS term
FROM documents;
```

La funci√≥n string_to_array se utiliza para dividir el contenido de los documentos en t√©rminos individuales, y la funci√≥n unnest se utiliza para convertir el resultado en filas individuales.

Lo siguiente es armar la relaci√≥n entre los documentos y t√©rminos. Esto se puede lograr utilizando consultas SQL que identifiquen los t√©rminos que aparecen en cada documento y los almacenen en la tabla de relaci√≥n. Por ejemplo:
```sql
INSERT INTO document_term (document_id, term)
SELECT d.id, t.term
FROM documents d
JOIN terms t ON lower(d.content) LIKE '%' || t.term || '%';
```
Una vez que se han extra√≠do los t√©rminos y se ha creado la tabla de relaci√≥n, se pueden crear √≠ndices en las columnas relevantes para mejorar el rendimiento de las consultas de b√∫squeda. Por lo general, se crean √≠ndices en las columnas de t√©rminos y en las columnas de identificadores de documentos para acelerar las b√∫squedas.

Con el √≠ndice invertido ya constru√≠do se pueden realizar consultas de b√∫squeda utilizando cl√°usulas SQL como WHERE y JOIN. Estas consultas aprovechan los √≠ndices para buscar r√°pidamente los documentos que contienen los t√©rminos de b√∫squeda especificados. Por tal motivo, las b√∫squedas de texto se vuelven m√°s eficientes, ya que se evita la necesidad de realizar exploraciones completas de los documentos.

# Backend (√çndice Multidimensional)



## KNN Secuencial: Priority Queue Search y Range Search



## KNN RTree



## KNN High D: Mitigaci√≥n de la dimensionalidad con FAISS



# Frontend (GUI)

## Mini-manual de usuarios
### Paso 1: Clonar el Repositorio

```bash
git clone https://github.com/Diegospf12/CapibaraGrooveFinder
cd CapibaraGrooveFinder
```

### Paso 2: Configuraci√≥n del Backend

Instalar dependencias
```bash
cd backend
source venv/bin/activate
pip install -r requirements.txt
```

Ejecutar servidor
```bash
cd backend
pip install -r requirements.txt
uvicorn main:app --reload
```

### Paso 3: Configuraci√≥n del Frontend

Instalar dependencias
```bash
cd frontend
npm install
npm run serve
```

## Screenshots
![[Main page]](https://github.com/Diegospf12/CapibaraGrooveFinder/blob/main/images/main.png)
![[Lyrics page]](https://github.com/Diegospf12/CapibaraGrooveFinder/blob/main/images/lyrics.png)
![[Similar page]](https://github.com/Diegospf12/CapibaraGrooveFinder/blob/main/images/similarpage.png)

## An√°lisis comparativo visual con otras implementaciones
![[Similar page]](https://github.com/Diegospf12/CapibaraGrooveFinder/blob/main/images/example1.png)
![[Similar page]](https://github.com/Diegospf12/CapibaraGrooveFinder/blob/main/images/example2.png)

# Experimentaci√≥n

## Tablas y gr√°ficos de los resultados experimentales

|      | Implementaci√≥n | Postgress |
|------|----------------|-----------|
| 1000 |     15 ms      |   19 ms   |
| 2000 |     34 ms      |   33 ms   |
| 4000 |     65 ms      |   72 ms   |
| 8000 |    190 ms      |  180 ms   |
|16000 |    295 ms      |  300 ms   |
|32000 |    333 ms      |  359 ms   |
|64000 |    380 ms      |  360 ms   |


### Implementaci√≥n de √çndice Invertido

Nuestra implementaci√≥n personalizada de √≠ndice invertido ha demostrado ser eficiente en la b√∫squeda de datos basada en texto. Hemos medido el rendimiento de nuestra implementaci√≥n en milisegundos para una variedad de tama√±os de datos de prueba, desde 1,000 hasta 64,000 registros. 

### PostgreSQL con √çndice Invertido

Por otro lado, hemos utilizado PostgreSQL con sus propios √≠ndices invertidos para realizar b√∫squedas de texto similares a nuestras pruebas con datos de prueba de tama√±os comparables.

## Tabla de resultados de √≠ndices multidimensionales

Ejecutamos el KNN-RTree, KNN-secuencial y el KNN-HighD sobre una colecci√≥n de objetos de tama√±o N y comparamos la eficiencia en funci√≥n del tiempo de ejecuci√≥n

|  k=8    | Secuencial |  KNN-RTree  |  KNN-HighD  |
|------|------------|-------------|-------------|
| 1000 | 0.05100 ms | 0.001276 ms | 0.053848 ms |
| 2000 | 0.08857 ms | 0.002307 ms | 0.087420 ms |
| 4000 | 0.16724 ms | 0.006453 ms | 0.155970 ms |
| 8000 | 0.28190 ms | 0.015350 ms | 0.256640 ms |
|12000 | 0.49926 ms | 0.026420 ms | 0.397190 ms |
|16000 | 0.63667 ms | 0.035708 ms | 0.486560 ms |

### Gr√°fico comparativo de tiempos

![graph2](https://github.com/Diegospf12/CapibaraGrooveFinder/blob/main/images/grafico_comparativo_2.png)


### An√°lisis y Discusi√≥n
- Podemos notar que el la b√∫squeda KNN con un RTree es la que menos tiempo demora, esto se debe a que a la hora de indexar los vectores, estos se transforman a un vector en 2D, por lo que a la hora de hacer una b√∫squeda el tiempo computacional ser√° menor a comparaci√≥n de la b√∫squeda secuencial y con el √≠ndice IVFFlat, los cual√©s hacen una b√∫squeda en 50D.

- El tiempo de la b√∫squeda secuencial va incrementando mucho a medida que se va incrementando la cantidad de vectores en la colecci√≥n, por lo que podemos notar que a la hora de b√∫squedas en altas dimensiones, el √≠ndice IVFFlat ser√° m√°s √≥ptimo.

- Nuestra implementaci√≥n de √≠ndice invertido a la hora de hacer el filtrado pierda algunos t√©rminos ya que estos pueden estar concatenados con s√≠mbolos raros (".!-) y esto puede ocacionar que la b√∫squeda de ciertos documentos que contienen estas palabras no sean exactos.

### Conclusi√≥n

Los resultados de nuestra comparaci√≥n indican que PostgreSQL supera ligeramente a nuestra implementaci√≥n personalizada de √≠ndice invertido en t√©rminos de rendimiento en la mayor√≠a de los escenarios. Aunque nuestra implementaci√≥n es eficiente, PostgreSQL, con su optimizaci√≥n interna y capacidad para manejar grandes conjuntos de datos, muestra tiempos de b√∫squeda ligeramente m√°s bajos en las pruebas. Por otro lado a la hora de b√∫squeda por similitud de audio, podemos darnos cuenta que la mejor opci√≥n fue el √çndice IVFFlat de Faiss ya que esye divide los audios por cl√∫sters, para asi reducir la cantidad de comparaciones.
